{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code performs sentiment analysis on labelled dataset by using \"roberta-base\" model and its evaluation metrics are also computed.\n",
    "We have used \"facebook/bart-large\" for trends extraction for comparing the output with finetuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNTTV7DtlG0l",
    "outputId": "99df6cf0-97c2-4b13-95d6-bb5b8c6acc26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Sentiment Analysis using \"roberta-base\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QheXgeLAkgLV",
    "outputId": "6a059781-cc17-4a4c-dc0b-db96d162c5b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa Sentiment Analysis Metrics:\n",
      "Accuracy: 0.5934\n",
      "Precision: 0.5934\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.7448\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import json\n",
    "\n",
    "# Load the tokenizer and model for sentiment analysis\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Create a pipeline with the model and tokenizer\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Load the dataset\n",
    "with open(\"/content/combined_dataset.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "sentences = []\n",
    "true_labels = []\n",
    "\n",
    "# Prepare the dataset\n",
    "# Ensure that each sentence is paired with its corresponding sentiment\n",
    "for entry in data:\n",
    "    for sentence in entry[\"sentence\"]:  # Iterate through sentences within each entry\n",
    "        sentences.append(sentence)\n",
    "        true_labels.append(entry[\"sentiment\"]) # Assign the sentiment to each sentence\n",
    "\n",
    "# Convert true labels to binary: \"positive\" -> 1, \"negative\" -> 0\n",
    "true_labels_binary = [1 if label == \"positive\" else 0 for label in true_labels]\n",
    "\n",
    "# Process sentences and handle length constraints\n",
    "predicted_labels_binary = []\n",
    "for sentence in sentences:\n",
    "    # Tokenize and truncate the input\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        # Predict sentiment\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        predicted_labels_binary.append(prediction)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels_binary, predicted_labels_binary)\n",
    "precision = precision_score(true_labels_binary, predicted_labels_binary)\n",
    "recall = recall_score(true_labels_binary, predicted_labels_binary)\n",
    "f1 = f1_score(true_labels_binary, predicted_labels_binary)\n",
    "\n",
    "# Print results\n",
    "print(\"RoBERTa Sentiment Analysis Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Trends Extraction using \"facebook/bart-large\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxFr9KMBocBP",
    "outputId": "abc48f29-60fe-4f2e-b81c-1f6a18e30a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n",
      "Evaluation Metrics for Facebook BART:\n",
      "Average ROUGE-1: 0.0000\n",
      "Average ROUGE-2: 0.0000\n",
      "Average ROUGE-L: 0.0000\n",
      "Mean Reciprocal Rank (MRR): 0.0345\n",
      "Precision@k: 0.0069\n",
      "Recall@k: 0.0345\n",
      "F1@k: 0.0115\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score\n",
    "\n",
    "import json\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Load data from JSON file\n",
    "file_path = \"/content/combined_dataset.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract sentences and trends from the loaded data\n",
    "sentences = [item[\"sentence\"] for item in data]\n",
    "trends = [item[\"trends\"] for item in data]\n",
    "\n",
    "# Ensure alignment of sentences and trends\n",
    "flat_sentences = []\n",
    "flat_trends = []\n",
    "\n",
    "for item in data:\n",
    "    for sentence in item[\"sentence\"]:\n",
    "        flat_sentences.append(sentence)\n",
    "        flat_trends.append(\"; \".join(item[\"trends\"]))  # Associate the same trends for all sentences in a group\n",
    "\n",
    "# Check alignment\n",
    "assert len(flat_sentences) == len(flat_trends), \"Mismatch in the number of sentences and trends.\"\n",
    "\n",
    "# Split the data into training and testing subsets\n",
    "train_texts, test_texts, train_trends, test_trends = train_test_split(\n",
    "    flat_sentences, flat_trends, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "model_name = \"facebook/bart-large\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to generate trends using BART\n",
    "def generate_trends(model, tokenizer, texts, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(\n",
    "                text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True\n",
    "            ).to(device)\n",
    "            outputs = model.generate(inputs[\"input_ids\"], max_length=50)\n",
    "            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            predictions.append(generated_text)\n",
    "    return predictions\n",
    "\n",
    "# Generate trends for the test set\n",
    "predicted_trends = generate_trends(model, tokenizer, test_texts, device)\n",
    "\n",
    "# Compute ROUGE metrics using rouge_scorer\n",
    "rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def evaluate_trends(actual_trends, predicted_trends, k=5):\n",
    "    rouge_1_scores, rouge_2_scores, rouge_l_scores = [], [], []\n",
    "    mrr_scores = []\n",
    "    precision_at_k = []\n",
    "    recall_at_k = []\n",
    "    f1_at_k = []\n",
    "\n",
    "    for actual, predicted in zip(actual_trends, predicted_trends):\n",
    "        # ROUGE scores\n",
    "        rouge_scores = rouge_scorer_obj.score(\" \".join(predicted.split()), \" \".join(actual.split()))\n",
    "        rouge_1_scores.append(rouge_scores['rouge1'].fmeasure)\n",
    "        rouge_2_scores.append(rouge_scores['rouge2'].fmeasure)\n",
    "        rouge_l_scores.append(rouge_scores['rougeL'].fmeasure)\n",
    "\n",
    "        # For MRR, Precision@k, Recall@k, F1@k, assume that each trend is a set of relevant keywords\n",
    "        actual_trends_set = set(actual.split(\"; \"))  # Actual trends split by semicolon\n",
    "        predicted_trends_list = predicted.split(\"; \")  # Predicted trends as list\n",
    "\n",
    "        # MRR Calculation\n",
    "        rank = next((i + 1 for i, trend in enumerate(predicted_trends_list) if trend in actual_trends_set), 0)\n",
    "        mrr_scores.append(1 / rank if rank != 0 else 0)\n",
    "\n",
    "        # Precision@k, Recall@k, F1@k (k = 5)\n",
    "        top_k_predictions = predicted_trends_list[:k]\n",
    "        relevant_predictions = set(top_k_predictions) & actual_trends_set\n",
    "\n",
    "        # Precision@k = Relevant Predictions / k\n",
    "        precision_at_k.append(len(relevant_predictions) / k)\n",
    "\n",
    "        # Recall@k = Relevant Predictions / Total Relevant\n",
    "        recall_at_k.append(len(relevant_predictions) / len(actual_trends_set))\n",
    "\n",
    "        # F1@k = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "        p_at_k = len(relevant_predictions) / k\n",
    "        r_at_k = len(relevant_predictions) / len(actual_trends_set)\n",
    "        f1_at_k.append(2 * (p_at_k * r_at_k) / (p_at_k + r_at_k) if (p_at_k + r_at_k) > 0 else 0)\n",
    "\n",
    "\n",
    "\n",
    "    # Average ROUGE scores\n",
    "    avg_rouge_1 = sum(rouge_1_scores) / len(rouge_1_scores)\n",
    "    avg_rouge_2 = sum(rouge_2_scores) / len(rouge_2_scores)\n",
    "    avg_rouge_l = sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "\n",
    "    # Average MRR, Precision@k, Recall@k, F1@k\n",
    "    avg_mrr = sum(mrr_scores) / len(mrr_scores)\n",
    "    avg_precision_at_k = sum(precision_at_k) / len(precision_at_k)\n",
    "    avg_recall_at_k = sum(recall_at_k) / len(recall_at_k)\n",
    "    avg_f1_at_k = sum(f1_at_k) / len(f1_at_k)\n",
    "\n",
    "    return {\n",
    "        \"Average ROUGE-1\": avg_rouge_1,\n",
    "        \"Average ROUGE-2\": avg_rouge_2,\n",
    "        \"Average ROUGE-L\": avg_rouge_l,\n",
    "        \"Mean Reciprocal Rank (MRR)\": avg_mrr,\n",
    "        \"Precision@k\": avg_precision_at_k,\n",
    "        \"Recall@k\": avg_recall_at_k,\n",
    "        \"F1@k\": avg_f1_at_k,\n",
    "    }\n",
    "\n",
    "# Helper function to flatten and get unique elements\n",
    "def flatten_and_unique(lst):\n",
    "    return list(set([item.strip().lower() for sublist in lst for item in sublist]))\n",
    "\n",
    "# Flatten and deduplicate\n",
    "flat_predicted = flatten_and_unique(predicted_trends)\n",
    "flat_actual = flatten_and_unique(test_trends)\n",
    "\n",
    "# Evaluate trends on the test set\n",
    "test_metrics = evaluate_trends(flat_actual, flat_predicted, k=5)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"Evaluation Metrics for Facebook BART:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
